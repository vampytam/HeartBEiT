python pretrain/run_beit_pretraining.py \
    --batch_size 64 \  # 每个批次的样本数量
    --epochs 300 \  # 训练的总轮数
    --save_ckpt_freq 20 \  # 保存检查点的频率（每20个epoch保存一次）
    --discrete_vae_weight_path "" \  # 离散VAE权重的路径
    --discrete_vae_type "dall-e" \  # 离散VAE的类型
    --model "beit_base_patch16_224_8k_vocab" \  # 要训练的模型名称
    --rel_pos_bias \  # 启用相对位置偏置
    --abs_pos_emb \  # 启用绝对位置嵌入
    --layer_scale_init_value 0.1 \  # 层缩放初始化值
    --num_mask_patches 75 \  # 需要掩蔽的视觉标记/补丁数量
    --min_mask_patches_per_block 16 \  # 每个块的最小掩蔽补丁数量
    --input_size 224 \  # 输入图像的大小
    --second_input_size 112 \  # 离散VAE的输入图像大小
    --drop_path 0.1 \  # Drop path的比率
    --opt "adamw" \  # 优化器类型
    --opt_eps 1e-8 \  # 优化器的epsilon值
    --opt_betas 0.9 0.999 \  # 优化器的beta值
    --momentum 0.9 \  # SGD动量
    --weight_decay 0.05 \  # 权重衰减
    --lr 5e-4 \  # 学习率
    --warmup_lr 1e-6 \  # 预热学习率
    --min_lr 1e-5 \  # 循环调度器的最低学习率
    --warmup_epochs 5 \  # 预热学习率的轮数
    --warmup_steps -1 \  # 预热学习率的步数
    --train_interpolation "bicubic" \  # 训练时的插值方法
    --second_interpolation "lanczos" \  # 离散VAE的插值方法
    --data_path "/datasets01/imagenet_full_size/061417/" \  # 数据集路径
    --imagenet_default_mean_and_std \  # 使用ImageNet的默认均值和标准差
    --output_dir "" \  # 保存模型的路径
    --log_dir None \  # TensorBoard日志的路径
    --device "cuda" \  # 训练/测试使用的设备
    --seed 0 \  # 随机种子
    --resume "" \  # 从检查点恢复的路径
    --auto_resume \  # 启用自动恢复
    --start_epoch 0 \  # 开始的epoch
    --num_workers 10 \  # 数据加载的工作线程数量
    --pin_mem \  # 在DataLoader中固定CPU内存以提高GPU传输效率
    --world_size 1 \  # 分布式进程的数量
    --local_rank -1 \  # 本地进程的排名
    --dist_on_itp \  # 启用ITP上的分布式训练
    --dist_url "env://"  # 用于设置分布式训练的URL